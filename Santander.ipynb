{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Santander.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xemiKKhh_bCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KzRnjqSOkXy",
        "colab_type": "code",
        "outputId": "216c06a1-61e6-455a-b58b-1bc5880bb3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "!git clone https://github.com/h2oai/pystacknet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pystacknet'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Total 42 (delta 0), reused 0 (delta 0), pack-reused 42\u001b[K\n",
            "Unpacking objects: 100% (42/42), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-8cVjab_upv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('./pystacknet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsRJyCsx_c-e",
        "colab_type": "code",
        "outputId": "d223668c-47c5-4a09-baf9-e2235dbe8459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1361
        }
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "warning: pypandoc module not found, could not convert Markdown to RST\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating pystacknet.egg-info\n",
            "writing pystacknet.egg-info/PKG-INFO\n",
            "writing dependency_links to pystacknet.egg-info/dependency_links.txt\n",
            "writing requirements to pystacknet.egg-info/requires.txt\n",
            "writing top-level names to pystacknet.egg-info/top_level.txt\n",
            "writing manifest file 'pystacknet.egg-info/SOURCES.txt'\n",
            "writing manifest file 'pystacknet.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/pystacknet\n",
            "copying pystacknet/pystacknet.py -> build/lib/pystacknet\n",
            "copying pystacknet/__init__.py -> build/lib/pystacknet\n",
            "copying pystacknet/metrics.py -> build/lib/pystacknet\n",
            "creating build/lib/pystacknet/test\n",
            "copying pystacknet/test/__init__.py -> build/lib/pystacknet/test\n",
            "copying pystacknet/test/test_amazon.py -> build/lib/pystacknet/test\n",
            "copying pystacknet/test/test_pystacknet.py -> build/lib/pystacknet/test\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/pystacknet\n",
            "creating build/bdist.linux-x86_64/egg/pystacknet/test\n",
            "copying build/lib/pystacknet/test/__init__.py -> build/bdist.linux-x86_64/egg/pystacknet/test\n",
            "copying build/lib/pystacknet/test/test_amazon.py -> build/bdist.linux-x86_64/egg/pystacknet/test\n",
            "copying build/lib/pystacknet/test/test_pystacknet.py -> build/bdist.linux-x86_64/egg/pystacknet/test\n",
            "copying build/lib/pystacknet/pystacknet.py -> build/bdist.linux-x86_64/egg/pystacknet\n",
            "copying build/lib/pystacknet/__init__.py -> build/bdist.linux-x86_64/egg/pystacknet\n",
            "copying build/lib/pystacknet/metrics.py -> build/bdist.linux-x86_64/egg/pystacknet\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pystacknet/test/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pystacknet/test/test_amazon.py to test_amazon.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pystacknet/test/test_pystacknet.py to test_pystacknet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pystacknet/pystacknet.py to pystacknet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pystacknet/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pystacknet/metrics.py to metrics.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pystacknet.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pystacknet.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pystacknet.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pystacknet.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pystacknet.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/pystacknet-0.0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing pystacknet-0.0.1-py3.6.egg\n",
            "Copying pystacknet-0.0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding pystacknet 0.0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/pystacknet-0.0.1-py3.6.egg\n",
            "Processing dependencies for pystacknet==0.0.1\n",
            "Searching for scikit-learn==0.20.3\n",
            "Best match: scikit-learn 0.20.3\n",
            "Adding scikit-learn 0.20.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.1.0\n",
            "Best match: scipy 1.1.0\n",
            "Adding scipy 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.14.6\n",
            "Best match: numpy 1.14.6\n",
            "Adding numpy 1.14.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for pystacknet==0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-osDWB6zxCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pystacknet.pystacknet import StackNetClassifier\n",
        "import numpy as np\n",
        "from pystacknet.pystacknet import StackNetClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn import preprocessing\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier,ExtraTreesRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNtx26a4skEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mNqPZKPsmcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup kaggle, so that you can get the dataset directly \n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uAhae9xOpdl",
        "colab_type": "code",
        "outputId": "af85f349-58e0-4ce8-b32a-0ce064b5b50f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!kaggle competitions download -c santander-customer-transaction-prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading train.csv.zip to /content\n",
            " 99% 121M/122M [00:00<00:00, 123MB/s]\n",
            "100% 122M/122M [00:00<00:00, 157MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/463k [00:00<?, ?B/s]\n",
            "100% 463k/463k [00:00<00:00, 49.6MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 88% 107M/122M [00:00<00:00, 102MB/s]  \n",
            "100% 122M/122M [00:01<00:00, 119MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLCY0yV5zXM0",
        "colab_type": "code",
        "outputId": "c7a6ff36-97a1-435a-9a3a-cda425b19c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "!unzip test.csv.zip \n",
        "!unzip train.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQOn5864z5uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv('train.csv')\n",
        "test=pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ti80VTW1oKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx = features = train.columns.values[2:202]\n",
        "for df in [test,train]:\n",
        "    df['sum'] = df[idx].sum(axis=1)  \n",
        "    df['min'] = df[idx].min(axis=1)\n",
        "    df['max'] = df[idx].max(axis=1)\n",
        "    df['mean'] = df[idx].mean(axis=1)\n",
        "    df['std'] = df[idx].std(axis=1)\n",
        "    df['skew'] = df[idx].skew(axis=1)\n",
        "    df['kurt'] = df[idx].kurtosis(axis=1)\n",
        "    df['med'] = df[idx].median(axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qraOiXx34Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_copy=train.copy()\n",
        "test_copy=test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOVsa3Sg4U7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = [c for c in train_copy.columns if c not in ['ID_code', 'target']]\n",
        "for feature in features:\n",
        "    train_copy['r2_'+feature] = np.round(train_copy[feature], 2)\n",
        "    test_copy['r2_'+feature] = np.round(test_copy[feature], 2)\n",
        "    train_copy['r1_'+feature] = np.round(train_copy[feature], 1)\n",
        "    test_copy['r1_'+feature] = np.round(test_copy[feature], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyqxwCdz6uee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=train_copy.drop(columns=['ID_code','target']).values\n",
        "y=train_copy.target.values\n",
        "X_test=test_copy.drop(columns=['ID_code']).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLWfmSxbB1Gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " models=[ \n",
        "            ######## First level ########\n",
        "            [#RandomForestClassifier (n_estimators=200, criterion=\"entropy\", max_depth=3, max_features=0.3, random_state=1,n_jobs=1),\n",
        "             #ExtraTreesClassifier (n_estimators=200, criterion=\"entropy\", max_depth=3, max_features=0.3, random_state=1,n_jobs=1),\n",
        "             #ExtraTreesRegressor (n_estimators=100, max_depth=5, max_features=0.3, random_state=1,n_jobs=1),\n",
        "             GradientBoostingClassifier(n_estimators=310,max_depth=5, max_features=0.5, random_state=1),\n",
        "             LogisticRegression(random_state=1),\n",
        "             XGBClassifier(max_depth=5, n_estimators=300, objective=\"binary:logistic\", booster=\"gbtree\", random_state=1,n_jobs=1 ),\n",
        "             LGBMClassifier(boosting_type='gbdt', num_leaves=10, max_depth= 6, learning_rate=0.01, n_estimators=300,objective=\"binary\",metric='auc',min_child_samples=10, subsample=0.9, subsample_freq=1, colsample_bytree=0.5,random_state=1, n_jobs=1)             \n",
        "\n",
        "             ],\n",
        "            ######## Second level ########\n",
        "            [RandomForestClassifier (n_estimators=300, criterion=\"entropy\", max_depth=5, max_features=0.7, random_state=1)]\n",
        "            ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTQju3T8HJwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=StackNetClassifier(models, metric=\"auc\", folds=3, restacking=True,\n",
        "                         use_retraining=True, use_proba=True, random_state=2019,\n",
        "                         n_jobs=1, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aE1b4V6HtGj",
        "colab_type": "code",
        "outputId": "20ef8db1-07d5-4934-ddf5-449b57b76427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        }
      },
      "source": [
        "model.fit(X,y )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================== Start of Level 0 ======================\n",
            "Input Dimensionality 624 at Level 0 \n",
            "4 models included in Level 0 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 1/3 , model 0 , auc===0.878276 \n",
            "Fold 1/3 , model 1 , auc===0.863501 \n",
            "Fold 1/3 , model 2 , auc===0.879268 \n",
            "Fold 1/3 , model 3 , auc===0.803974 \n",
            "=========== end of fold 1 in level 0 ===========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 2/3 , model 0 , auc===0.880347 \n",
            "Fold 2/3 , model 1 , auc===0.868142 \n",
            "Fold 2/3 , model 2 , auc===0.881669 \n",
            "Fold 2/3 , model 3 , auc===0.808664 \n",
            "=========== end of fold 2 in level 0 ===========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 3/3 , model 0 , auc===0.876615 \n",
            "Fold 3/3 , model 1 , auc===0.863809 \n",
            "Fold 3/3 , model 2 , auc===0.877583 \n",
            "Fold 3/3 , model 3 , auc===0.808174 \n",
            "=========== end of fold 3 in level 0 ===========\n",
            "Level 0, model 0 , auc===0.878413 \n",
            "Level 0, model 1 , auc===0.865151 \n",
            "Level 0, model 2 , auc===0.879507 \n",
            "Level 0, model 3 , auc===0.806937 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Output dimensionality of level 0 is 4 \n",
            "====================== End of Level 0 ======================\n",
            " level 0 lasted 28819.425099 seconds \n",
            "====================== Start of Level 1 ======================\n",
            "Input Dimensionality 628 at Level 1 \n",
            "1 models included in Level 1 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjIxivrGHxTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds=model.predict_proba(X_test)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA1p2NhztSjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_copy['target']=preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xni40H0jteis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission=test_copy[['ID_code','target']]\n",
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOdG9JXEtnro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('submission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohcB9lcttqhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions submit -c santander-customer-transaction-prediction -f submission.csv -m \"Message\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO4x02H1tsou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}